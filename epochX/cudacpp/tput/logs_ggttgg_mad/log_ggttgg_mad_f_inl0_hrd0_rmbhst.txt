
Building in /data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg
BACKEND=cpp512y (was cppauto)
OMPFLAGS=
FPTYPE='d'
HELINL='0'
HRDCOD='0'
HASCURAND=hasCurand
HASHIPRAND=hasNoHiprand
Building in BUILDDIR=build.auto_d_inl0_hrd0 for tag=512y_d_inl0_hrd0_hasCurand_hasNoHiprand (USEBUILDDIR == 1)
make: Nothing to be done for 'gtestlibs'.

make USEBUILDDIR=1 BACKEND=cuda
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

make USEBUILDDIR=1 BACKEND=cppnone
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

make USEBUILDDIR=1 BACKEND=cppsse4
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

make USEBUILDDIR=1 BACKEND=cppavx2
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

make USEBUILDDIR=1 BACKEND=cpp512y
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

make USEBUILDDIR=1 BACKEND=cpp512z
make[1]: Entering directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg'

DATE: 2024-07-17_15:17:37

On itscrd90.cern.ch [CPU: Intel(R) Xeon(R) Silver 4216 CPU] [GPU: 1x Tesla V100S-PCIE-32GB]:
=========================================================================
runExe /data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg/build.cuda_f_inl0_hrd0/check_cuda.exe -p 64 256 1 --rmbhst OMP=
WARNING! RamboHost selected: cannot use CurandDevice, will use CurandHost
INFO: The following Floating Point Exceptions will cause SIGFPE program aborts: FE_DIVBYZERO, FE_INVALID, FE_OVERFLOW
Process                     = SIGMA_SM_GG_TTXGG_CUDA [nvcc 12.0.140 (gcc 11.3.1)] [inlineHel=0] [hardcodePARAM=0]
Workflow summary            = CUD:FLT+THX:CURHST+RMBHST+MESDEV/none+NAVBRK
FP precision                = FLOAT (NaN/abnormal=0, zero=0)
EvtsPerSec[Rmb+ME]     (23) = ( 5.605343e+05                 )  sec^-1
EvtsPerSec[MatrixElems] (3) = ( 6.227941e+05                 )  sec^-1
EvtsPerSec[MECalcOnly] (3a) = ( 6.233063e+05                 )  sec^-1
MeanMatrixElemValue         = ( 4.048178e+00 +- 2.364571e+00 )  GeV^-4
TOTAL       :     0.143333 sec
INFO: No Floating Point Exceptions have been reported
       509,021,990      cycles                           #    2.836 GHz                    
       744,440,585      instructions                     #    1.46  insn per cycle         
       0.182068265 seconds time elapsed
runNcu /data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg/build.cuda_f_inl0_hrd0/check_cuda.exe -p 64 256 1 --rmbhst
WARNING! RamboHost selected: cannot use CurandDevice, will use CurandHost
==PROF== Profiling "sigmaKin": launch__registers_per_thread 255
==PROF== Profiling "sigmaKin": sm__sass_average_branch_targets_threads_uniform.pct 100%
.........................................................................
runExe /data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg/build.cuda_f_inl0_hrd0/check_cuda.exe -p 2048 256 1 --rmbhst OMP=
WARNING! RamboHost selected: cannot use CurandDevice, will use CurandHost
INFO: The following Floating Point Exceptions will cause SIGFPE program aborts: FE_DIVBYZERO, FE_INVALID, FE_OVERFLOW
Process                     = SIGMA_SM_GG_TTXGG_CUDA [nvcc 12.0.140 (gcc 11.3.1)] [inlineHel=0] [hardcodePARAM=0]
Workflow summary            = CUD:FLT+THX:CURHST+RMBHST+MESDEV/none+NAVBRK
FP precision                = FLOAT (NaN/abnormal=0, zero=0)
EvtsPerSec[Rmb+ME]     (23) = ( 7.127362e+05                 )  sec^-1
EvtsPerSec[MatrixElems] (3) = ( 8.218448e+05                 )  sec^-1
EvtsPerSec[MECalcOnly] (3a) = ( 8.221215e+05                 )  sec^-1
MeanMatrixElemValue         = ( 6.641709e+00 +- 4.994248e+00 )  GeV^-4
TOTAL       :     1.585920 sec
INFO: No Floating Point Exceptions have been reported
     4,766,594,292      cycles                           #    2.916 GHz                    
    11,234,187,248      instructions                     #    2.36  insn per cycle         
       1.638426706 seconds time elapsed
-------------------------------------------------------------------------
runExe /data/avalassi/GPU2023/madgraph4gpuX/epochX/cudacpp/gg_ttgg.mad/SubProcesses/P1_gg_ttxgg/build.cuda_f_inl0_hrd0/runTest_cuda.exe
runTest_cuda.exe: GpuRuntime.h:26: void assertGpu(cudaError_t, const char*, int, bool): Assertion `code == gpuSuccess' failed.
